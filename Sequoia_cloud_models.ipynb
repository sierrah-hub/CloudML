{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of sequoia_cloud_models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRBNDY08Nn9L"
      },
      "source": [
        "This is the dataset currently loaded:\n",
        "\n",
        "1. [Sparcs Dataset ~2GB](https://www.usgs.gov/core-science-systems/nli/landsat/spatial-procedures-automated-removal-cloud-and-shadow-sparcs)\n",
        "  1. satellite tiff file (format w/ multiple channels, i.e. infrared as well as RGB)\n",
        "  2. txt metadata about the image\n",
        "  3. a satellite image png\n",
        "  4. a satellite mask png (with colors representing masks)\n",
        "\n",
        "These are some other options we have:\n",
        "\n",
        "1. [Landsat Validation Data ~100GB](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-8-cloud-cover-assessment-validation-data?qt-science_support_page_related_con=1#qt-science_support_page_related_con)\n",
        "\n",
        "2. [Kaggle Dataset ~20GB](https://www.kaggle.com/sorour/95cloud-cloud-segmentation-on-satellite-images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3YcRyg-4ZeT"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_id = '15_GVb8BRHpDYKMwBmPlF7KaklBBJIKO-'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('clouds.zip')\n",
        "\n",
        "!unzip -q clouds.zip -d /content/\n",
        "dataset_path = '/content/gdrive/MyDrive/sequoia/clouds'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhNeBSAF8GWL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import Sequential, layers, preprocessing \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# convenience key-word args to parallel process\n",
        "parallel_map_kwargs = dict(\n",
        "  num_parallel_calls=tf.data.AUTOTUNE,\n",
        "  deterministic=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og1fJ6-u94ke"
      },
      "source": [
        "# #### DOWNLOAD THE SPARCS DATASET ####\n",
        "# def download(data_url):\n",
        "#   dl_manager = tfds.download.DownloadManager(download_dir='junk', extract_dir='/content/clouds')\n",
        "#   dataset_path = dl_manager.download_and_extract(data_url)\n",
        "#   return dataset_path\n",
        "\n",
        "# # creates a dataset consisting of image file paths\n",
        "# SPARCS_DATA_URL = 'https://landsat.usgs.gov/cloud-validation/sparcs/l8cloudmasks.zip'\n",
        "# dataset_path = download(SPARCS_DATA_URL) + \"/sending\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc3OLjwQYJx1"
      },
      "source": [
        "#### READ IMAGE & MASK TO DATASET ####\n",
        "def read_img_and_mask(img_path: tf.Tensor):\n",
        "    # read img at specified path\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_png(img)\n",
        "\n",
        "    # read corresponding mask (whose path replaces 'photo' w/ 'mask')\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"photo\", \"mask\")\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    \n",
        "    # tuple of img and mask\n",
        "    return img, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZL1HTs2Rjfd"
      },
      "source": [
        "ds = tf.data.Dataset.list_files(dataset_path + '/*photo.png')\n",
        "# read in each image and its mask using those file paths \n",
        "\n",
        "ds = ds.map(read_img_and_mask, **parallel_map_kwargs)\n",
        "\n",
        "# size of dataset\n",
        "CARDINALITY = ds.cardinality()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFL3wo9zN6bD"
      },
      "source": [
        "# take n random crops of an image and its mask\n",
        "@tf.function\n",
        "def sample_crop(img, mask, w, h, n):\n",
        "  img_and_mask = tf.experimental.numpy.dstack((img, mask))\n",
        "  crops = [tf.image.random_crop(img_and_mask, (w, h, 4)) for i in range(n)]\n",
        "  crops = tf.stack(crops)\n",
        "  crops = tf.data.Dataset.from_tensor_slices(crops)\n",
        "  return crops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QX2p1tZ287"
      },
      "source": [
        "# randomly crop each img (and its mask) several times\n",
        "n, w, h = 5, 128, 128\n",
        "ds = ds.interleave(lambda img, mask: sample_crop(img, mask, w, h, n), **parallel_map_kwargs)\n",
        "\n",
        "# tf doesn't know cardinality after interleave, so we help it out\n",
        "CARDINALITY *= n\n",
        "ds = ds.apply(tf.data.experimental.assert_cardinality(CARDINALITY))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2K983q_pLXR"
      },
      "source": [
        "# represent as tuple of img, mask rather than mask stacked beneath image\n",
        "ds = ds.map(lambda x: (x[:, :, 0:3], x[:, :, 3]), **parallel_map_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2cGpL3dwKI2"
      },
      "source": [
        "@tf.function\n",
        "def cloud_score(img, mask):  \n",
        "  # cloud mask is 5\n",
        "  clouds = tf.math.count_nonzero(mask == 255)\n",
        "  cloud_score = clouds / tf.size(mask, out_type=tf.int64)\n",
        "  return img, cloud_score\n",
        "\n",
        "ds = ds.map(cloud_score, **parallel_map_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOqZRQZRqvnb"
      },
      "source": [
        "# random shuffle\n",
        "ds = ds.shuffle(buffer_size=CARDINALITY)\n",
        "\n",
        "train_ds_size = int(3 * CARDINALITY // 5) # 60\n",
        "valid_ds_size = int(CARDINALITY // 5) # 20\n",
        "\n",
        "train_ds = ds.take(train_ds_size)\n",
        "remaining = ds.skip(train_ds_size)  \n",
        "valid_ds = remaining.take(valid_ds_size)\n",
        "test_ds = remaining.skip(valid_ds_size)\n",
        "\n",
        "train_ds = train_ds.batch(256).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(256).prefetch(tf.data.AUTOTUNE)\n",
        "valid_ds = valid_ds.batch(256).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBbAAQBQpVNx"
      },
      "source": [
        "num_classes = 1\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(h, w, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZmrkOGSqGNM"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.MeanSquaredError())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI7H8LH-BDKZ"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    restore_best_weights=True,\n",
        "    patience=5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpo_eFmCqJdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "540bf2e9-5cc0-458e-b07f-f43e7d41cd92"
      },
      "source": [
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=valid_ds,\n",
        "  epochs=15,\n",
        "  callbacks=[callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.1438 - val_loss: 0.0758\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0932 - val_loss: 0.0579\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0911 - val_loss: 0.0729\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0796 - val_loss: 0.0734\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0834 - val_loss: 0.0571\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0661 - val_loss: 0.0833\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0733 - val_loss: 0.0683\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.0748 - val_loss: 0.1056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2FnFATlH5Az",
        "outputId": "cbf51c0c-90b8-4f29-b0b8-0c6bc33db7c9"
      },
      "source": [
        "model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step - loss: 0.0561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.056101810187101364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh4dnJzpR0r8"
      },
      "source": [
        "actuals, diffs = [], []\n",
        "\n",
        "for img, score in test_ds:\n",
        "  actual = score.numpy()\n",
        "  pred = model.predict(img).squeeze()\n",
        "  diff = actual - pred\n",
        "  \n",
        "  actuals.append(actual)\n",
        "  diffs.append(diff)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "tsn4FIFmX8vf",
        "outputId": "f797566c-62c6-470b-ca0e-6f843b587c6a"
      },
      "source": [
        "actuals = np.concatenate(actuals)\n",
        "diffs = np.concatenate(diffs)\n",
        "\n",
        "plt.scatter(actuals, np.abs(diffs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f73b8cf6610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}